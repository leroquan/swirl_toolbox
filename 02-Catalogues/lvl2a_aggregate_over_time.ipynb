{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "108f85d9c4eb58dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model = 'geneva_200m'\n",
    "params_file = 'swirl_03'\n",
    "output_folder = r'../Outputs'\n",
    "\n",
    "lvl1_filename = f'{model}_{params_file}_day1_lvl1.csv'\n",
    "output_filename = f'{model}_{params_file}_day1_lvl2.csv'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc195934c0a8ca39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "level1_csv_path = os.path.join(output_folder, lvl1_filename)\n",
    "level1_data = pd.read_csv(level1_csv_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1839e31700b02673"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def ranges_intersect(min1, max1, min2, max2):\n",
    "    return max1 >= min2 and max2 >= min1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c459ffdfefd1539"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "id_eddy=2\n",
    "dist_threshold = 20 # in number of cells\n",
    "time_threshold = 2 # in number of timestep\n",
    "\n",
    "mask = (\n",
    "    level1_data.apply(lambda row: ranges_intersect(row['depth_min_[m]'],row['depth_max_[m]'],level1_data.at[id_eddy, 'depth_min_[m]'],level1_data.at[id_eddy, 'depth_max_[m]']), axis=1) &\n",
    "    (level1_data['rotation_direction'] == level1_data.at[id_eddy, 'rotation_direction']) &\n",
    "    (np.sqrt((level1_data['xc_mean'] - level1_data.at[id_eddy, 'xc_mean'])**2 + (level1_data['yc_mean'] - level1_data.at[id_eddy, 'yc_mean'])**2) < dist_threshold)\n",
    ")\n",
    "\n",
    "filtered_eddies = level1_data.loc[mask]\n",
    "filtered_eddies = filtered_eddies.copy()\n",
    "filtered_eddies['parsed_date'] = pd.to_datetime(filtered_eddies['date'])\n",
    "\n",
    "sorted_by_date = filtered_eddies.sort_values('parsed_date', ascending=True).reset_index(drop=False)\n",
    "\n",
    "for i in range(1,len(sorted_by_date)):\n",
    "    if sorted_by_date.iloc[i]['time_index'] - sorted_by_date.iloc[i-1]['time_index'] > time_threshold:\n",
    "        drop_idxs = sorted_by_date.index[i:]\n",
    "        sorted_by_date = sorted_by_date.drop(index=drop_idxs)            \n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "650ca1370b6bda00"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sorted_by_date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdef97031e0e7050"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to identify the different depths of an eddy\n",
    "def track_eddy(level1_data, id_eddy, idx_already_aggregated, dist_threshold, time_threshold):\n",
    "    mask = (\n",
    "        (~level1_data['id'].isin(idx_already_aggregated)) &\n",
    "        level1_data.apply(lambda row: ranges_intersect(row['depth_min_[m]'],row['depth_max_[m]'],level1_data.at[id_eddy, 'depth_min_[m]'],level1_data.at[id_eddy, 'depth_max_[m]']), axis=1) &\n",
    "        (level1_data['rotation_direction'] == level1_data.at[id_eddy, 'rotation_direction']) &\n",
    "        (np.sqrt((level1_data['xc_mean'] - level1_data.at[id_eddy, 'xc_mean'])**2 + (level1_data['yc_mean'] - level1_data.at[id_eddy, 'yc_mean'])**2) < dist_threshold)\n",
    "    )\n",
    "    \n",
    "    filtered_eddies = level1_data.loc[mask]\n",
    "    filtered_eddies = filtered_eddies.copy()\n",
    "    filtered_eddies['parsed_date'] = pd.to_datetime(filtered_eddies['date'])\n",
    "\n",
    "    sorted_by_date = filtered_eddies.sort_values('parsed_date', ascending=True).reset_index(drop=False)\n",
    "    \n",
    "    for i in range(1,len(sorted_by_date)):\n",
    "        if sorted_by_date.iloc[i]['time_index'] - sorted_by_date.iloc[i-1]['time_index'] > time_threshold:\n",
    "            drop_idxs = sorted_by_date.index[i:]\n",
    "            sorted_by_date = sorted_by_date.drop(index=drop_idxs)            \n",
    "            break\n",
    "    \n",
    "    return sorted_by_date"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a5f0fa84f2455a0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dist_threshold = 20 # in number of cells\n",
    "time_threshold = 1 # in number of timestep\n",
    "timestep_in_seconds = 3600\n",
    "\n",
    "# Main loop\n",
    "eddy_rows_lvl2a= []  # Collect aggregated rows here\n",
    "id_level2a = 0\n",
    "idx_already_aggregated = set()\n",
    "for idx in level1_data['id']: \n",
    "    if idx in idx_already_aggregated:\n",
    "        continue\n",
    "        \n",
    "    aggregated_data = track_eddy(level1_data, idx, idx_already_aggregated, dist_threshold, time_threshold)\n",
    "    lifespan = (timestep_in_seconds + (pd.to_datetime(aggregated_data['date'].iloc[-1]) - pd.to_datetime(aggregated_data['date'].iloc[0])).total_seconds()) / 3600\n",
    "\n",
    "    row = {\n",
    "        'id': id_level2a,\n",
    "        'id_lvl1': aggregated_data['id'].tolist(),\n",
    "        'time_indices(t)': aggregated_data['time_index'].tolist(),\n",
    "        'dates(t)': aggregated_data['date'].tolist(),\n",
    "        'xc(t)': aggregated_data['xc_mean'].tolist(),\n",
    "        'yc(t)': aggregated_data['yc_mean'].tolist(),\n",
    "        'volume(t)_[m3]': aggregated_data['volume_[m3]'].tolist(),\n",
    "        'rotation_direction': aggregated_data.at[0, 'rotation_direction'],\n",
    "        'kinetic_energy(t)_[MJ]': aggregated_data['kinetic_energy_[MJ]'].tolist(),\n",
    "        'lifespan_[h]': lifespan\n",
    "    }\n",
    "\n",
    "    eddy_rows_lvl2a.append(row)\n",
    "    idx_already_aggregated.update(aggregated_data['id'].tolist())\n",
    "    id_level2a += 1\n",
    "\n",
    "# Create the final DataFrame using pd.concat\n",
    "df_catalogue_level2 = pd.concat([pd.DataFrame([row]) for row in eddy_rows_lvl2a], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebd35e276a325640"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_catalogue_level2.to_csv(os.path.join(output_folder, output_filename), index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9b1df834796a039"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
